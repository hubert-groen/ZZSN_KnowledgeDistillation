{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logits and train indices\n",
    "N_MODELS = 100\n",
    "N_CLASSES = 10\n",
    "teacher_logits_zip = np.load(f\"./saves/logits/logits_resnet_0.npz\")\n",
    "teacher_logits = np.concatenate([teacher_logits_zip['logits_arr_train'], teacher_logits_zip['logits_arr_test']])\n",
    "targets = np.concatenate([teacher_logits_zip['targets_arr_train'], teacher_logits_zip['targets_arr_test']])\n",
    "teacher_train_indices = np.load(\"./indices/train_idx_0.npy\")\n",
    "\n",
    "student_logits = np.empty((N_MODELS, 60000, 10), dtype=np.float32)\n",
    "student_train_indices = np.empty((N_MODELS, 30000))\n",
    "for idx in range(1, N_MODELS+1):\n",
    "    x = np.load(f\"./saves/logits/logits_resnet_{idx}.npz\")\n",
    "    x = np.concatenate([x['logits_arr_train'], x['logits_arr_test']])\n",
    "    student_logits[idx-1,:,:] = x\n",
    "    student_train_indices[idx-1,:] = np.load(f\"./indices/train_idx_{idx}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all logits to confidence scores\n",
    "loss = CrossEntropyLoss(reduction='none')\n",
    "teacher_losses = np.empty((60000, 10))\n",
    "for class_nr in range(N_CLASSES):\n",
    "    teacher_losses[:, class_nr] = loss(torch.Tensor(teacher_logits), torch.Tensor(60000*[class_nr]).type(torch.LongTensor)).numpy()\n",
    "teacher_cfs = np.exp(-1 * teacher_losses)\n",
    "\n",
    "student_losses = np.empty((N_MODELS, 60000, 10))\n",
    "for k in range(1, N_MODELS+1):\n",
    "    for class_nr in range(N_CLASSES):  \n",
    "        student_losses[k-1, :, class_nr] = loss(torch.Tensor(student_logits[k-1,:]), torch.Tensor(60000*[class_nr]).type(torch.LongTensor)).numpy()\n",
    "student_cfs = np.exp(-1 * student_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerically stable way to apply logit scaling to confidence scores\n",
    "mask = np.ones((60000, N_CLASSES), dtype=bool)\n",
    "mask[range(60000), list(targets.astype(np.int64))] = False\n",
    "teacher_cfs_wrong = teacher_cfs[mask].reshape(60000, N_CLASSES-1)\n",
    "teacher_logits = np.log(np.choose(list(targets.astype(np.int64)), teacher_cfs.T)+1e-45) - np.log(teacher_cfs_wrong.sum(1)+1e-45)\n",
    "\n",
    "student_logits = np.empty((N_MODELS, 60000))\n",
    "for k in range(1, N_MODELS+1):\n",
    "    mask = np.ones((60000, N_CLASSES), dtype=bool)\n",
    "    mask[range(60000), list(targets.astype(np.int64))] = False\n",
    "    student_cfs_wrong = student_cfs[k-1, :, :][mask].reshape(60000, N_CLASSES-1)\n",
    "    student_logits[k-1, :] = np.log(np.choose(list(targets.astype(np.int64)), student_cfs[k-1, :, :].T)+1e-45) - np.log(student_cfs_wrong.sum(1)+1e-45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting normal dist foe teacher\n",
    "import seaborn as sns\n",
    "plt.style.use(\"ggplot\")\n",
    "idx_in_train_dataset = np.array([True if idx in teacher_train_indices else False for idx in range(0, 60000)])\n",
    "in_scores = teacher_logits[idx_in_train_dataset]\n",
    "out_scores = teacher_logits[~idx_in_train_dataset]\n",
    "minn = min(min(in_scores), min(out_scores))\n",
    "maxx = max(max(in_scores), max(out_scores))\n",
    "bins = np.arange(minn, maxx, 1)\n",
    "a = sns.histplot([in_scores, out_scores], bins=bins)\n",
    "\n",
    "s_in = np.std(in_scores)\n",
    "m_in = np.mean(in_scores)\n",
    "s_out = np.std(out_scores)\n",
    "m_out = np.mean(out_scores)\n",
    "x_ticks = np.arange(minn, maxx, 0.01)\n",
    "norm_in = scipy.stats.norm.pdf(x_ticks, m_in, s_in)\n",
    "norm_out = scipy.stats.norm.pdf(x_ticks, m_out, s_out)\n",
    "coef_in = max([bar.get_height() for bar in a.containers[1]]) / max(norm_in)\n",
    "coef_out = max([bar.get_height() for bar in a.containers[0]]) / max(norm_out)\n",
    "\n",
    "plt.plot(x_ticks, coef_in*norm_in)\n",
    "plt.plot(x_ticks, coef_out*norm_out)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(['IN scores', 'OUT scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting normal dist\n",
    "import seaborn as sns\n",
    "sample_nr = 30878\n",
    "idx_in_train_dataset = np.any(student_train_indices == sample_nr, axis=1)\n",
    "in_scores = student_logits[idx_in_train_dataset, sample_nr]\n",
    "out_scores = student_logits[~idx_in_train_dataset, sample_nr]\n",
    "minn = min(min(in_scores), min(out_scores))\n",
    "maxx = max(max(in_scores), max(out_scores))\n",
    "bins = np.arange(minn, maxx, 1)\n",
    "a = sns.histplot([in_scores, out_scores], bins=bins)\n",
    "\n",
    "s_in = np.std(in_scores)\n",
    "m_in = np.mean(in_scores)\n",
    "s_out = np.std(out_scores)\n",
    "m_out = np.mean(out_scores)\n",
    "x_ticks = np.arange(minn, maxx, 0.01)\n",
    "norm_in = scipy.stats.norm.pdf(x_ticks, m_in, s_in)\n",
    "norm_out = scipy.stats.norm.pdf(x_ticks, m_out, s_out)\n",
    "coef_in = max([bar.get_height() for bar in a.containers[1]]) / max(norm_in)\n",
    "coef_out = max([bar.get_height() for bar in a.containers[0]]) / max(norm_out)\n",
    "\n",
    "plt.plot(x_ticks, coef_in*norm_in)\n",
    "plt.plot(x_ticks, coef_out*norm_out)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(['IN scores', 'OUT scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "for num_models in [20,40,60,80,100]:\n",
    "    member_indicators = []\n",
    "    member_scores = []\n",
    "    skipped = 0\n",
    "\n",
    "    for train_idx in tqdm.tqdm(range(0, 60000)):\n",
    "        idx_in_train_dataset = np.any(student_train_indices[:num_models] == train_idx, axis=1)\n",
    "\n",
    "        # get IN models logits\n",
    "        in_logits = student_logits[:num_models][idx_in_train_dataset][:, train_idx]\n",
    "\n",
    "        # get OUT models logits\n",
    "        out_logits = student_logits[:num_models][~idx_in_train_dataset][:, train_idx]\n",
    "\n",
    "        # get teacher model logit\n",
    "        teacher_logit = teacher_logits[train_idx]\n",
    "\n",
    "        if len(in_logits)/num_models > 0.65 or len(out_logits)/num_models > 0.65:\n",
    "            #print(f\"Unbalanced data for idx {train_idx}. Skipping ...\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Calibrate normal dist for IN\n",
    "        s_in = np.std(in_logits)\n",
    "        m_in = np.mean(in_logits)\n",
    "\n",
    "        # Calibrate normal dist for OUT\n",
    "        s_out = np.std(out_logits)\n",
    "        m_out = np.mean(out_logits)\n",
    "\n",
    "        # # Ensure s_in and s_out are not zero to avoid division by zero\n",
    "        # if s_in == 0:\n",
    "        #     s_in = 1e-10\n",
    "        # if s_out == 0:\n",
    "        #     s_out = 1e-10\n",
    "\n",
    "        # Set is_member indicator for sample\n",
    "        if train_idx in teacher_train_indices:\n",
    "            member_indicators.append(1)\n",
    "        else:\n",
    "            member_indicators.append(0)\n",
    "\n",
    "        # Calculate is_member score for sample\n",
    "        score = scipy.stats.norm.pdf(teacher_logit, m_in, s_in) / (scipy.stats.norm.pdf(teacher_logit, m_out, s_out) + 1e-40)\n",
    "        member_scores.append(score)\n",
    "\n",
    "    print(f\"Skipped: {skipped}/60000 for {num_models} models\")\n",
    "    3/0\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(member_indicators,  member_scores)\n",
    "    auc = metrics.roc_auc_score(member_indicators,  member_scores)\n",
    "    plt.loglog(fpr, tpr, label=f'{num_models} models, AUC={auc:.4f}')\n",
    "\n",
    "\n",
    "# Comparison to simple loss attack\n",
    "member_indicators = []\n",
    "member_scores = []\n",
    "\n",
    "for train_idx in tqdm.tqdm(range(0, 60000)):\n",
    "\n",
    "    # Set is_member indicator for sample\n",
    "    if train_idx in teacher_train_indices:\n",
    "        member_indicators.append(1)\n",
    "    else:\n",
    "        member_indicators.append(0)\n",
    "\n",
    "    # Calculate is_member score for sample\n",
    "    score = -1 * teacher_losses[train_idx, int(targets[train_idx])]\n",
    "    member_scores.append(score)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(member_indicators,  member_scores)\n",
    "auc = metrics.roc_auc_score(member_indicators,  member_scores)\n",
    "plt.loglog(fpr, tpr, label=f'Simple loss attack, AUC={auc:.4f}')\n",
    "\n",
    "plt.xlim(10**-5,  1)\n",
    "plt.ylim(10**-5,  1)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
